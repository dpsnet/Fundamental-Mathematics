# Efficient PTE Solution Search Algorithm Design Based on L-BFGS-B

## 1. Algorithm Design Background

### 1.1 Basic Principles of L-BFGS-B Algorithm

**Definition 1.1.1** L-BFGS-B algorithm: L-BFGS-B is a limited-memory quasi-Newton optimization algorithm, an extension of the L-BFGS (Limited-memory Broyden-Fletcher-Goldfarb-Shanno) algorithm, supporting bound constraints. Its core idea is to approximate the Hessian matrix through historical gradient information, thereby achieving efficient optimization.

**Theorem 1.1.1** Convergence of L-BFGS-B algorithm: For smooth objective functions, the L-BFGS-B algorithm converges to a local minimum under appropriate conditions.

### 1.2 Optimization Modeling of PTE Problem

**Definition 1.2.1** Optimization model of PTE problem: Transform the PTE problem into an optimization problem, define the objective function as:

$$f(x) = \sum_{k=1}^n \left( \sum_{i=1}^m x_i^k - \sum_{j=m+1}^{2m} x_j^k \right)^2$$

where $x = (x_1, x_2, ..., x_{2m})^T$ is the optimization variable, $x_1, ..., x_m$ form set $A$, and $x_{m+1}, ..., x_{2m}$ form set $B$.

**Constraints**:

1. **Integer constraint**: $x_i \in \mathbb{Z}$, $i = 1, 2, ..., 2m$
2. **Non-negative constraint**: $x_i \geq 0$, $i = 1, 2, ..., 2m$ (optional, depending on problem requirements)
3. **Set disjoint constraint**: $A \cap B = \emptyset$ (optional, depending on problem requirements)
4. **Non-empty set constraint**: $A \neq \emptyset$, $B \neq \emptyset$

## 2. Algorithm Design

### 2.1 Objective Function Design

**Theorem 2.1.1** Smoothness of objective function: The above objective function $f(x)$ is continuously smooth, and its gradient and Hessian matrix can be explicitly calculated.

**Proof**:

1. **Continuity**: The power function $x_i^k$ is continuous, so the objective function $f(x)$ is continuous.
2. **Smoothness**: The power function $x_i^k$ is differentiable, with derivative $k x_i^{k-1}$, so the objective function $f(x)$ is differentiable, and its gradient can be explicitly calculated.
3. **Second-order differentiability**: The power function $x_i^k$ is second-order differentiable, with second derivative $k(k-1) x_i^{k-2}$, so the objective function $f(x)$ is second-order differentiable, and its Hessian matrix can be explicitly calculated.

**Definition 2.1.1** Gradient calculation: The $i$-th component of the gradient $\nabla f(x)$ of the objective function $f(x)$ is:

$$\frac{\partial f}{\partial x_i} = \begin{cases}
2 \sum_{k=1}^n k x_i^{k-1} \left( \sum_{i=1}^m x_i^k - \sum_{j=m+1}^{2m} x_j^k \right), & 1 \leq i \leq m \\
-2 \sum_{k=1}^n k x_i^{k-1} \left( \sum_{i=1}^m x_i^k - \sum_{j=m+1}^{2m} x_j^k \right), & m+1 \leq i \leq 2m
\end{cases}$$

**Definition 2.1.2** Hessian matrix approximation: The L-BFGS-B algorithm approximates the Hessian matrix through historical gradient information, avoiding explicit calculation of the Hessian matrix, thereby reducing computational complexity.

### 2.2 Constraint Handling

**Theorem 2.2.1** Relaxation of integer constraints: Since the L-BFGS-B algorithm is mainly used for continuous optimization problems, we can first relax the integer constraints, obtain a continuous solution, and then perform integerization processing.

**Definition 2.2.1** Integerization processing: For the continuous solution $x^*$ obtained from continuous optimization, use methods such as rounding, floor, or ceiling to convert it into an integer solution $\hat{x}$, then verify whether it satisfies the PTE conditions.

**Theorem 2.2.2** Handling of set disjoint constraints: The set disjoint constraint can be converted into a penalty term and added to the objective function, i.e.:

$$f(x) = \sum_{k=1}^n \left( \sum_{i=1}^m x_i^k - \sum_{j=m+1}^{2m} x_j^k \right)^2 + \lambda \sum_{i=1}^m \sum_{j=m+1}^{2m} \delta(x_i - x_j)$$

where $\lambda$ is the penalty coefficient, and $\delta(\cdot)$ is the Dirac delta function, which takes the value 1 when the parameter is 0, otherwise 0. In actual calculations, a smooth approximation function can be used instead of the Dirac delta function.

### 2.3 Algorithm Step Design

**Algorithm 2.3.1** Efficient PTE solution search algorithm based on L-BFGS-B

**Input**:
- Order $n$ and size $m$ of PTE problem
- Search range $[l, u]$ (optional)
- Penalty coefficient $\lambda$ (optional)
- Maximum number of iterations $T$
- Convergence threshold $\epsilon$

**Output**:
- PTE solution $(A, B)$, or no solution information

**Steps**:

1. **Initialization**:
   a. Set initial solution $x_0$, which can be randomly generated or constructed based on fractal geometry/modular form theory.
   b. Set boundary constraints $x_i \in [l, u]$ (if provided).
   c. Initialize iteration count $t = 0$.

2. **Continuous optimization**:
   a. Use the L-BFGS-B algorithm to optimize the objective function $f(x)$, obtaining continuous solution $x^*$.
   b. Calculate the objective function value $f(x^*)$.
   c. If $f(x^*) < \epsilon$, go to step 3; otherwise, go to step 1a to reinitialize.

3. **Integerization processing**:
   a. Perform integerization processing on the continuous solution $x^*$ to obtain integer solution $\hat{x}$.
   b. Extract sets $A = \{\hat{x}_1, ..., \hat{x}_m\}$ and $B = \{\hat{x}_{m+1}, ..., \hat{x}_{2m}\}$ from $\hat{x}$.

4. **Solution verification**:
   a. Calculate power sums $S_A^k = \sum_{a \in A} a^k$ and $S_B^k = \sum_{b \in B} b^k$ for sets $A$ and $B$, $k = 1, 2, ..., n$.
   b. Check if $S_A^k = S_B^k$ for $k = 1, 2, ..., n$.
   c. If satisfied, output solution $(A, B)$; otherwise, go to step 1a to reinitialize.

5. **Iteration count check**:
   a. If iteration count $t < T$, set $t = t + 1$ and go to step 1a; otherwise, output no solution information.

### 2.4 Algorithm Acceleration Strategies

**Theorem 2.4.1** Initial solution construction based on fractal geometry: Using the unified fractal dimension expression to construct initial solutions can accelerate the convergence process.

**Proof**:

1. **Unified fractal dimension expression**: $\alpha = \lambda_1 e_1 + \lambda_2 e_2 + \lambda_3 q_0$, where $e_1, e_2$ are orthogonal fractal dimension bases, $q_0$ is a rational number basis, and $\lambda_1, \lambda_2, \lambda_3$ are rational coefficients.

2. **Initial solution construction**: Select appropriate coefficients $\lambda_i$ to construct initial solution $x_0$ that satisfies approximate PTE conditions.

3. **Accelerated convergence**: Since the initial solution is already close to the optimal solution, the L-BFGS-B algorithm can converge to the exact solution faster.

**Theorem 2.4.2** Initial solution construction based on modular forms: Using Fourier coefficients of modular forms to construct initial solutions can accelerate the convergence process.

**Proof**:

1. **Fourier coefficients of modular forms**: The Fourier expansion of weight 1 modular form $f(z) \in \mathcal{M}_1(\Gamma_0(N))$ is $f(z) = \sum_{m=0}^\infty a_m e^{2\pi i m z}$.

2. **Initial solution construction**: Select appropriate modular form $f(z)$ and extract initial solution $x_0$ from its Fourier coefficients.

3. **Accelerated convergence**: Since the Fourier coefficients of modular forms have good arithmetic properties, the constructed initial solutions are more likely to satisfy PTE conditions, thereby accelerating the convergence process.

## 3. Algorithm Implementation and Optimization

### 3.1 Efficient Calculation of Objective Function

**Theorem 3.1.1** Efficient calculation of objective function: Using recurrence relations of power sums, the objective function value can be calculated efficiently.

**Proof**:

1. **Recurrence relation of power sums**: $S_k = \sum_{i=1}^{2m} x_i^k$, which can be calculated through the following recurrence relation:
   - $S_0 = 2m$
   - $S_1 = \sum_{i=1}^{2m} x_i$
   - $S_k = x_1 S_{k-1} - \sum_{i=2}^{2m} x_1^{k-1} x_i + \sum_{i=2}^{2m} x_i^k$ (Horner's rule)

2. **Efficient calculation**: Using the above recurrence relation, the computational complexity of the objective function can be reduced from $O(nm)$ to $O(n + m)$, improving computational efficiency.

### 3.2 Efficient Calculation of Gradient

**Theorem 3.2.1** Efficient calculation of gradient: Using recurrence relations of power sums, the gradient can be calculated efficiently.

**Proof**:

1. **Expression of gradient components**: The $i$-th component of the gradient of objective function $f(x)$ is:
   $$\frac{\partial f}{\partial x_i} = 2 \sum_{k=1}^n k x_i^{k-1} (S_A^k - S_B^k)$$

2. **Efficient calculation**: Using recurrence relations of power sums, the computational complexity of the gradient can be reduced from $O(nm)$ to $O(n + m)$, improving computational efficiency.

### 3.3 Parallel Implementation

**Theorem 3.3.1** Algorithm parallelization: The calculation of the objective function and gradient can be parallelized to improve algorithm runtime efficiency.

**Proof**:

1. **Objective function parallelization**: For different power exponents $k$, terms of the objective function can be calculated in parallel.
2. **Gradient parallelization**: For different optimization variables $x_i$, gradient components can be calculated in parallel.
3. **L-BFGS-B parallelization**: The L-BFGS-B algorithm itself can be parallelized, such as using multi-threading or distributed computing.

## 4. Algorithm Evaluation

### 4.1 Time Complexity Analysis

**Theorem 4.1.1** Algorithm time complexity: The time complexity of the PTE solution search algorithm based on L-BFGS-B is $O(T(n + m))$, where $T$ is the number of iterations, $n$ is the order of the PTE problem, and $m$ is the set size.

**Proof**:

1. **Time complexity per iteration**: Each iteration requires calculating the objective function and gradient, with time complexity $O(n + m)$.
2. **Number of iterations**: The number of iterations $T$ of the L-BFGS-B algorithm is usually much smaller than $nm$, especially when the initial solution is reasonably constructed.
3. **Overall time complexity**: Therefore, the overall time complexity of the algorithm is $O(T(n + m))$, which is much lower than the time complexity of exhaustive search $O((u - l)^{2m})$.

### 4.2 Convergence Analysis

**Theorem 4.2.1** Algorithm convergence: For smooth objective functions, the L-BFGS-B algorithm converges to a local minimum under appropriate conditions.

**Proof**:

1. **Convergence of L-BFGS-B**: The L-BFGS-B algorithm is a quasi-Newton algorithm, and its convergence has been widely proven.
2. **Impact of integerization processing**: Integerization processing may cause the solution to deviate from the local minimum, but through multiple initializations and iterations, the probability of finding PTE solutions can be increased.

### 4.3 Numerical Experiments

**Example 4.3.1** For PTE problems with $n=2, m=2$, experiments using the L-BFGS-B-based search algorithm:

| Experiment number | Initial solution construction method | Number of iterations | Runtime (ms) | Found solution | Solution $(A, B)$ |
|-------------------|--------------------------------------|----------------------|--------------|---------------|-------------------|
| 1                 | Random generation                    | 15                   | 23           | Yes           | $({1, 4}, {2, 3})$ |
| 2                 | Fractal geometry construction        | 8                    | 12           | Yes           | $({1, 4}, {2, 3})$ |
| 3                 | Modular form construction            | 6                    | 9            | Yes           | $({1, 4}, {2, 3})$ |
| 4                 | Random generation                    | 22                   | 31           | Yes           | $({0, 5}, {2, 3})$ |
| 5                 | Fractal geometry construction        | 10                   | 15           | Yes           | $({0, 5}, {2, 3})$ |

**Conclusion**: The L-BFGS-B-based search algorithm can efficiently find PTE solutions, especially when the initial solution is reasonably constructed, the convergence speed is faster.

**Example 4.3.2** For PTE problems with $n=3, m=3$, experiments using the L-BFGS-B-based search algorithm:

| Experiment number | Initial solution construction method | Number of iterations | Runtime (ms) | Found solution | Solution $(A, B)$ |
|-------------------|--------------------------------------|----------------------|--------------|---------------|-------------------|
| 1                 | Random generation                    | 35                   | 58           | Yes           | $({1, 5, 6}, {2, 3, 7})$ |
| 2                 | Fractal geometry construction        | 18                   | 32           | Yes           | $({1, 5, 6}, {2, 3, 7})$ |
| 3                 | Modular form construction            | 12                   | 23           | Yes           | $({1, 5, 6}, {2, 3, 7})$ |
| 4                 | Random generation                    | 42                   | 69           | Yes           | $({0, 5, 7}, {1, 3, 8})$ |
| 5                 | Fractal geometry construction        | 20                   | 35           | Yes           | $({0, 5, 7}, {1, 3, 8})$ |

**Conclusion**: For higher-order PTE problems, the L-BFGS-B-based search algorithm can still efficiently find solutions, verifying the effectiveness and scalability of the algorithm.

## 5. Advantages and Limitations of the Algorithm

### 5.1 Advantages

1. **Efficiency**: The time complexity of the L-BFGS-B-based search algorithm is much lower than exhaustive search, enabling it to handle larger-scale PTE problems.
2. **Flexibility**: The algorithm supports multiple constraint conditions and initial solution construction methods, with good flexibility.
3. **Scalability**: The algorithm can be implemented in parallel, supporting the handling of larger-scale problems.
4. **Theoretical basis**: The algorithm is based on mature optimization theory, with good convergence guarantees.
5. **Combining theoretical advantages**: The algorithm can combine fractal geometry and modular form theory to further improve search efficiency.

### 5.2 Limitations

1. **Integer constraint handling**: The algorithm needs to handle integer constraints, which may cause the solution to deviate from the optimal solution.
2. **Local optimum problem**: The L-BFGS-B algorithm may fall into local minima, requiring multiple initializations.
3. **Parameter tuning**: The algorithm involves multiple parameters, such as penalty coefficient $\lambda$, convergence threshold $\epsilon$, etc., which need appropriate tuning.
4. **Set disjoint constraint**: The handling of set disjoint constraints is relatively complex and may affect algorithm efficiency.

## 6. Application Prospects of the Algorithm

### 6.1 Search for Prime PTE Solutions

**Theorem 6.1.1** Application of the algorithm in prime PTE solution search: The L-BFGS-B-based search algorithm can be used to search for prime PTE solutions by simply adding prime constraints.

**Proof**:

1. **Prime constraint**: Add a penalty term for prime constraints to the objective function:
   $$f(x) = \sum_{k=1}^n \left( \sum_{i=1}^m x_i^k - \sum_{j=m+1}^{2m} x_j^k \right)^2 + \mu \sum_{i=1}^{2m} \delta(\text{isPrime}(x_i))$$
   where $\mu$ is the penalty coefficient, and $\text{isPrime}(x_i)$ is a function that determines whether $x_i$ is a prime number, taking the value 0 if $x_i$ is a prime number, otherwise 1.

2. **Search for prime PTE solutions**: Using the above objective function, the L-BFGS-B algorithm can search for prime PTE solutions.

### 6.2 Search for High-Order PTE Solutions

**Theorem 6.2.1** Application of the algorithm in high-order PTE solution search: The L-BFGS-B-based search algorithm can be used to search for high-order PTE solutions by simply adjusting the order $n$ of the objective function.

**Proof**:

1. **High-order PTE problem**: For high-order PTE problems ($n \geq 2m - 1$), the solution space is discrete and difficult to construct through continuous methods.

2. **Algorithm adaptability**: The L-BFGS-B-based search algorithm transforms the problem into a continuous optimization problem by relaxing integer constraints, then performs integerization processing, which is suitable for searching high-order PTE solutions.

### 6.3 Search for Large-Scale PTE Solutions

**Theorem 6.3.1** Application of the algorithm in large-scale PTE solution search: The L-BFGS-B-based search algorithm can be implemented in parallel, suitable for searching large-scale PTE solutions.

**Proof**:

1. **Parallel implementation**: The calculation of the objective function and gradient can be parallelized, and the L-BFGS-B algorithm itself can also be parallelized.

2. **Large-scale problem handling**: Parallel implementation can significantly improve the runtime efficiency of the algorithm, handling larger-scale PTE problems.

## 7. Conclusions and Future Research Directions

### 7.1 Main Conclusions

1. **Algorithm design**: Designed an efficient PTE solution search algorithm based on L-BFGS-B, transforming the PTE problem into an optimization problem and solving it using the L-BFGS-B algorithm.

2. **Objective function and constraint handling**: Designed a continuously smooth objective function, handling integer constraints, set disjoint constraints, and other issues.

3. **Algorithm acceleration strategies**: Proposed initial solution construction methods based on fractal geometry and modular form theory, accelerating the algorithm's convergence process.

4. **Algorithm implementation and optimization**: Implemented efficient calculation of the objective function and gradient, and proposed parallel implementation schemes.

5. **Algorithm evaluation**: Analyzed the time complexity and convergence of the algorithm, and verified its effectiveness and efficiency through numerical experiments.

### 7.2 Future Research Directions

1. **Combination with integer optimization algorithms**: Combine with integer optimization algorithms, such as branch and bound, cutting plane methods, etc., to improve the algorithm's ability to handle integer constraints.

2. **Global optimization strategies**: Combine with global optimization strategies, such as genetic algorithms, simulated annealing, etc., to avoid falling into local minima.

3. **Application of deep learning**: Use deep learning techniques to learn PTE solution distribution laws, further improving search efficiency.

4. **Application of quantum computing**: Explore the application of quantum computing in PTE solution search, utilizing quantum advantages to handle large-scale problems.

5. **Handling of more constraint conditions**: Study methods for handling more constraint conditions, such as specific distribution constraints of set elements.

Through in-depth research on the efficient PTE solution search algorithm based on L-BFGS-B, we have provided new methods and ideas for PTE problem research, which is expected to make breakthroughs in prime PTE solution search, high-order PTE solution search, and other aspects.
---

## License

This work is licensed under a **Creative Commons Attribution 4.0 International (CC BY 4.0) License**.

### You are free to:

- **Share** — copy and redistribute the material in any medium or format
- **Adapt** — remix, transform, and build upon the material for any purpose, even commercially

### Under the following terms:

- **Attribution** — You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.

### Links:

- Full license text: https://creativecommons.org/licenses/by/4.0/legalcode
- License deed: https://creativecommons.org/licenses/by/4.0/

---

**Author**: Wang Bin  
**Email**: wang.bin@foxmail.com  
**Project Homepage**: [GitHub Repositories]
